model="ema_limit"
exp="en/qat/a8w8"

CUDA_VISIBLE_DEVICES=4,5,6,7 python ${model}/qat.py \
    --world-size 4 \
    --num-epochs 200 \
    --start-epoch 1 \
    --ft-path exp/en/qat/continual/e200-avg64-a8w8.pt \
    --exp-dir exp/$exp \
    --full-libri 1 \
    --max-duration 2400 \
    --master-port 54325 \
    --use-fp16 False \
    --encoder-norm SyncBatchNorm \
    --channels 256 \
    --channels-expansion 1024 \
    --dilations-version 11 \
    --kernel-size 8 \
    --encoder-activation ReLU \
    --encoder-se-activation ReLU \
    --zero-init-residual True \
    --se-gate tanh \
    --ema-gamma 0.97 \
    --chunksize 8 \
    --encoder-dim 512 \
    --decoder-dim 256 \
    --joiner-dim 256 \
    --encoder-dropout 0.075 \
    --act-bal False \
    --whitener False \
    --n-bits-act 8 \
    --n-bits-weight 8 \
    --model-warmup-step 0 \
    --initial-lr 0.0001 \
    --data-libri-train True \
    --data-libri-dev-clean True \
    --data-libri-dev-other True \
    --enable-musan True \
    --enable-spec-aug True \
    --bpe-model data/en/lang_bpe_500/bpe.model \
    --manifest-dir data/en/fbank \
    --cutset-text text \
    --num-workers 2 \
    --simple-loss-scale 0.5 \
    --optimizer-name Eve \
    --weight-decay 0.001 \
    --scheduler-name ExponentialWarmupLR \
    --lr-warmup-iterations 3000 \
    --lr-gamma 0.98 \
    --min-utt-duration 1.0 \
    --max-utt-duration 20.0
