model="ema_q_hybrid"
exp="en/qat_ft/a8w8_omni_max_nolearng_lrcos5e-4"
CUDA_VISIBLE_DEVICES=4,5,7 ${model}/qat.py \
    --world-size 3 \
    --num-epochs 100 \
    --start-epoch 1 \
    --ft-path-start exp/en/default_2/epoch-136.pt \
    --ft-path-end exp/en/default_2/epoch-200.pt \
    --exp-dir exp/$exp \
    --full-libri 1 \
    --max-duration 2400 \
    --master-port 54327 \
    --use-fp16 True \
    --encoder-norm SyncBatchNorm \
    --channels 256 \
    --channels-expansion 1024 \
    --dilations-version 11 \
    --kernel-size 8 \
    --encoder-activation ReLU \
    --encoder-se-activation ReLU \
    --skip residual \
    --zero-init-residual True \
    --se-gate tanh \
    --ema-gamma 0.97 \
    --chunksize 8 \
    --encoder-dim 512 \
    --decoder-dim 256 \
    --joiner-dim 256 \
    --encoder-dropout 0.075 \
    --act-bal False \
    --whitener False \
    --eps 1.0e-2 \
    --n-bits-act 8 \
    --n-bits-weight 8 \
    --weight-quantizer-mode max \
    --quantizer-decay 0.95 \
    --quantizer-quantile 1.0 \
    --quantizer-learnable-gamma False \
    --quantizer-gamma-min 0.01 \
    --quantizer-gamma-max 1.0 \
    --data-libri-train True \
    --data-libri-dev-clean True \
    --data-libri-dev-other True \
    --bpe-model data/en/lang_bpe_500/bpe.model \
    --manifest-dir data/en/fbank \
    --cutset-text text \
    --num-workers 2 \
    --simple-loss-scale 0.5 \
    --optimizer-name Eve \
    --weight-decay 0.001 \
    --initial-lr 5e-4 \
    --scheduler-name CosineWarmupLR \
    --lr-warmup-iterations 0 \
    --lr-eta-min 1.0e-5 \
    --min-utt-duration 1.0 \
    --max-utt-duration 20.0
